{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universidade Federal de Santa Catarina<br>\n",
    "Departamento de Engenharia Elétrica e Eletrônica<br>\n",
    "EEL7514/EEL7513 - Introdução ao Aprendizado de Máquina\n",
    "$\\newcommand{\\bX}{\\mathbf{X}}$\n",
    "$\\newcommand{\\bw}{\\mathbf{w}}$\n",
    "$\\newcommand{\\by}{\\mathbf{y}}$\n",
    "$\\newcommand{\\bx}{\\mathbf{x}}$\n",
    "\n",
    "\n",
    "# Exercício 3: Regressão Logística\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Instruções gerais\n",
    "\n",
    "Nas questões abaixo (exceto na questão opcional), **todo o conjunto de dados** será usado como conjunto de treinamento. Não usaremos conjunto de validação ou teste.\n",
    "\n",
    "Em todas as questões, além da implemenação você deve incluir também uma **análise** dos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Conjunto de dados #1\n",
    "\n",
    "O primeiro conjunto de dados que usaremos, disponibilizado no arquivo `data1.txt`, fornece a pontuação de alunos em dois exames e a decisão se o aluno é aceito em uma universidade.\n",
    "\n",
    "1. Treine um classificador por regressão logística sem regularização e trace um gráfico mostrando o conjunto de dados e as regiões de decisão. Reporte também a taxa de erro (= # de classificações erradas / tamanho do conjunto). Note que taxa de erro é diferente de função custo do treinamento.\n",
    "\n",
    "2. Repita o item anterior adicionando mais atributos até obter 100% de acerto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para efetuar a otimização, usaremos o otimizador do SciPy, o que, além de implementar métodos mais eficientes que o método do gradiente, possui a vantagem de não precisarmos escolher a taxa de aprendizagem. \n",
    "\n",
    "Utilize a seguinte chamada:\n",
    "\n",
    "```python\n",
    "import scipy.optimize as opt\n",
    "def train(X,y):\n",
    "    w = opt.minimize(fun=cost, x0=np.zeros(X.shape[1]), jac=gradient, args=(X,y)).x\n",
    "    return w\n",
    "```\n",
    "\n",
    "onde as funções\n",
    "\n",
    "```python\n",
    "def cost(w, X, y):\n",
    "    return J\n",
    "\n",
    "def gradient(w, X, y):\n",
    "    return grad_J.flatten()\n",
    "```\n",
    "\n",
    "devem aceitar vetores 1-D como `w` (utilize `reshape` quando necessário). Da mesma forma, o vetor `w` retornado pelo otimizador é um vetor 1-D.\n",
    "\n",
    "As seguintes funções podem ser úteis:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def plotDataset(X, y):\n",
    "    y = y.flatten()\n",
    "    plt.plot(X[y==0,1],X[y==0,2],'bo',X[y==1,1],X[y==1,2],'rx')\n",
    "\n",
    "def plotBoundary(X, w, N=1000):\n",
    "    x1 = np.linspace(X[:,1].min(), X[:,1].max(), N)\n",
    "    x2 = np.linspace(X[:,2].min(), X[:,2].max(), N)\n",
    "    xx1, xx2 = np.meshgrid(x1, x2)\n",
    "    X = np.column_stack((xx1.reshape(-1),xx2.reshape(-1)))\n",
    "    X = mapFeature(X)\n",
    "    y_hat = predict(X,w).reshape(xx1.shape)\n",
    "    y_hat = (y_hat>=0.5)*2-1\n",
    "    plt.contourf(xx1,xx2,y_hat,cmap=plt.cm.bwr,vmin=-5,vmax=5)\n",
    "```\n",
    "\n",
    "as quais assumem que os atributos originais estão nas colunas 1 e 2 e que o mapeamento de atributos (incluindo adição de 1's) é dado pela função `mapFeature`.\n",
    "\n",
    "**Obs:** Caso deseje realizar normalização de atributos, isto **não** deve ser feito pela função `mapFeature`, mas sim internamente à função `train`, retornando um vetor de parâmetros que possa ser usado com os atributos não-normalizados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Conjunto de dados #2\n",
    "\n",
    "O segundo conjunto de dados que usaremos, disponibilizado no arquivo `data2.txt`, relaciona os resultados de dois testes realizados em microchips, bem como a decisão se o microchip passou ou não no controle de qualidade.\n",
    "\n",
    "1. Treine um classificador por regressão logística sem regularização e trace um gráfico mostrando o conjunto de dados e as regiões de decisão. Reporte também a taxa de erro (= # de classificações erradas / tamanho do conjunto).\n",
    "\n",
    "2. Repita o item anterior adicionando atributos polinomiais, incluindo termos cruzados (até no máximo grau 6).\n",
    "\n",
    "3. Adicione regularização no treinamento, ajuste o parâmetro de regularização e verifique qualitativamente a variação das regiões de decisão, bem como da taxa de acerto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Conjunto de dados #3\n",
    "\n",
    "O terceiro conjunto de dados que usaremos pode ser encontrado aqui:\n",
    "\n",
    "https://www.kaggle.com/uciml/iris/data\n",
    "\n",
    "O objetivo é implementar um classificador para classificar entre três tipos de plantas. Implemente apenas regressão logística sem regularização com os atributos originais, e reporte a taxa de erro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. (OPCIONAL) Conjunto de dados #4\n",
    "\n",
    "O último conjunto de dados, disponibilizado no arquivo `modulations.csv`, consiste de atributos extraídos de sinais de telecomunicações que utilizam dois tipos de modulação digital (PSK=0 ou FSK=1). O objetivo é classificar a modulação usada.\n",
    "\n",
    "Separe 20% dos dados como conjunto de teste e tente minimizar a taxa de erro neste conjunto, usando regressão logística."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
